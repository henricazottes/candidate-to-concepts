{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json source\n",
    "import json\n",
    "from os import path\n",
    "\n",
    "SourceData = json.load(open(path.abspath('./data/data.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\massa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (1.19.6)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_PATH = path.abspath('./data/generated/input')\n",
    "\n",
    "def saveText(type, candidat, filename, contentStr):\n",
    "    final_dir = path.join(OUTPUT_PATH, type, candidat)\n",
    "    if not os.path.exists(final_dir):\n",
    "        os.makedirs(final_dir)\n",
    "    with open(path.join(final_dir, filename), encoding='utf-8', mode='w') as f:\n",
    "        f.write(contentStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import fitz\n",
    "\n",
    "def pdfToText(byteArray):\n",
    "    doc = fitz.open(\"x.pdf\", byteArray)\n",
    "    pages = [ doc[ i ] for i in range( doc.pageCount ) ]\n",
    "\n",
    "    return '\\n---PAGE---\\n'.join([page.get_text('text') for page in pages])\n",
    "\n",
    "def downloadPdf(candidat, current_url):\n",
    "    resp = requests.get(current_url)\n",
    "    if resp.status_code != 200:\n",
    "        print(\"ERROR ({}) for {}\".format(resp.status_code, current_url))\n",
    "    else:\n",
    "        filename = current_url.split(\"/\")[-1]\n",
    "        saveText('pdf', candidat, filename+\".txt\", pdfToText(resp.content))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def downloadHtml(candidat, current_url):\n",
    "    resp = requests.get(current_url)\n",
    "    if resp.status_code != 200:\n",
    "        print(\"ERROR ({}) for {}\".format(resp.status_code, current_url))\n",
    "    else:\n",
    "        filename = (current_url[:-1] if (current_url.endswith(\"/\")) else current_url).split(\"/\")[-1]\n",
    "        fullContent = resp.content\n",
    "        soup = BeautifulSoup(fullContent, features=\"html.parser\")\n",
    "        for script in soup([\"script\", \"style\", \"nav\"]):\n",
    "            script.extract()\n",
    "        \n",
    "        if candidat == \"macron\" or candidat == \"pecresse\":\n",
    "            # On doit supprimer ler html si il y a : data-elementor-type=\"footer\"\n",
    "            for elem in soup.find_all('div', {'data-elementor-type': \"footer\"}):\n",
    "                elem.decompose()\n",
    "            for elem in soup.find_all('div', {'data-elementor-type': \"header\"}):\n",
    "                elem.decompose()\n",
    "        \n",
    "        if candidat == \"macron\":\n",
    "            for elem in soup.find_all('section', {'data-id': \"5d859698\"}):\n",
    "                elem.decompose()\n",
    "\n",
    "        if candidat == \"poutou\":\n",
    "            # On doit supprimer ler html si il y a : data-elementor-type=\"footer\"\n",
    "            for elem in soup.find_all('div', {'id': \"header-outer-wrapper-sticky-wrapper\"}):\n",
    "                elem.decompose()\n",
    "            for elem in soup.find_all('footer'):\n",
    "                elem.decompose()\n",
    "        \n",
    "        cleanText = soup.get_text()\n",
    "        cleanTextWithoutEmpty = re.sub(r'(\\n\\s*)+\\n+', '\\n\\n', cleanText)\n",
    "        saveText('html', candidat, filename+\".html.txt\", cleanTextWithoutEmpty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files\n",
    "for candidat in SourceData:\n",
    "    for current_url in SourceData[candidat]:\n",
    "        if current_url.endswith(\".pdf\"):\n",
    "            downloadPdf(candidat, current_url)\n",
    "        else:\n",
    "            downloadHtml(candidat, current_url)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ccbb2cd523f8445c02e4df7b4d61a10f4e94fd25c0e85e0febb2d13eee849992"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
