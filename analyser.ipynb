{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk, path\n",
    "import fitz\n",
    "\n",
    "INPUT_PDF_PATH = path.abspath('./data/input/pdfs')\n",
    "OUTPUT_TXT_PATH = path.abspath('./data/output/txt')\n",
    "OUTPUT_JSON_PATH = path.abspath('./data/output/json')\n",
    "\n",
    "def pdfToText(path):\n",
    "    doc = fitz.open(path)\n",
    "    pages = [ doc[ i ] for i in range( doc.pageCount ) ]\n",
    "\n",
    "    return ''.join([page.get_text('text') for page in pages])\n",
    "\n",
    "dirnames = next(walk(INPUT_PDF_PATH), (None, [], None))[1]  # [] if no file\n",
    "\n",
    "for dirname in dirnames:\n",
    "    filenames = next(walk(f'{INPUT_PDF_PATH}/{dirname}'), (None, None, []))[2]  # [] if no file\n",
    "    pdf_filenames = [filename for filename in filenames if filename.endswith('.pdf')]\n",
    "\n",
    "    output_filepath = path.join(OUTPUT_TXT_PATH, f'{dirname}.txt')\n",
    "    with open(output_filepath, 'w+') as file:\n",
    "        for filename in pdf_filenames:\n",
    "            text = pdfToText(path.join(INPUT_PDF_PATH, f'{dirname}/{filename}'))\n",
    "            file.write(text)\n",
    "\n",
    "filenames = next(walk(OUTPUT_TXT_PATH), (None, None, []))[2]  # [] if no file\n",
    "filepaths = [path.join(OUTPUT_TXT_PATH, filename) for filename in filenames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_contents = {}\n",
    "\n",
    "for filepath in filepaths:\n",
    "    filename = filepath.split('/')[-1].replace('.txt', '')\n",
    "    with open(filepath, 'r') as file:\n",
    "        raw_contents[filename] = file.read()\n",
    "\n",
    "with open('./data/stop-words/fr.txt') as file:\n",
    "    stop_words = file.read().splitlines()\n",
    "\n",
    "# print([content[0:100] for filename, content in raw_contents.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "file_words = {}\n",
    "\n",
    "for filename, raw_content in raw_contents.items():\n",
    "    words = re.sub(\"[!,’:%«»•())“/\\-\\.\\s\\d]+\", \"\\n\", raw_content).lower().split()\n",
    "    file_words[filename] = words\n",
    "\n",
    "# print([words[0:10] for filename, words in file_words.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_filtered_words = {}\n",
    "\n",
    "for filename, words in file_words.items():\n",
    "    filtered_words = [word for word in words if word not in stop_words ]\n",
    "    file_filtered_words[filename] = filtered_words\n",
    "\n",
    "# print([filtered_words[0:10] for filename, filtered_words in file_filtered_words.items()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_count_dicts = {}\n",
    "\n",
    "for filename, filtered_words in file_filtered_words.items():\n",
    "    count_dict = {}\n",
    "    for current_word in filtered_words:\n",
    "        if current_word not in count_dict:\n",
    "            count = len([word for word in filtered_words if word == current_word ])\n",
    "            count_dict[current_word] = count\n",
    "    \n",
    "    file_count_dicts[filename] = count_dict\n",
    "\n",
    "# print([list(count_dict.keys())[0:10] for filename, count_dict in file_count_dicts.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for filename, count_dict in file_count_dicts.items():\n",
    "    count_list = list(count_dict.items())\n",
    "    count_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    result = dict(count_list)\n",
    "    results[filename] = result\n",
    "\n",
    "# print([list(result.keys())[0:10] for filename, result in results.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for filename, result in results.items():\n",
    "    output_filepath = path.join(OUTPUT_JSON_PATH, f'{filename}.json')\n",
    "\n",
    "    with open(output_filepath, 'w', encoding='utf-8') as file:\n",
    "        json.dump(result, file, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "candidates-to-concepts",
   "language": "python",
   "name": "candidates-to-concepts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
